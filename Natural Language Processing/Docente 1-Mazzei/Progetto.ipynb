{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CKY.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Import necessari"],"metadata":{"id":"A2vYSBs3IvD7"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"xn0ukHiJjvQJ"},"outputs":[],"source":["import numpy as np\n","import re\n","from tabulate import tabulate"]},{"cell_type":"markdown","source":["#English Context-free grammar"],"metadata":{"id":"RddE2FcqIpGX"}},{"cell_type":"code","source":["English_Grammar = {\n","      # Grammatica che produce le frasi seguenti\n","    \"S\": [\"NP VP\", \"ANP VP\", \"book\", \"include\", \"prefer\", \"Verb NP\", \"VNP PP\", \"Verb PP\", \"VP PP\"],\n","    \"ANP\": [\"Aux NP\"],\n","    \"NP\": [\"I\", \"She\", \"Me\", \"TWA\", \"Houston\", \"Det Nominal\"], \n","    \"Nominal\": [\"book\", \"flight\", \"meal\", \"money\", \"morning\", \"Nominal Noun\", \"Nominal PP\"], \n","    \"Noun\": [\"book\", \"flight\", \"morning\"],\n","    \"Det\": [\"that\", \"this\", \"the\", \"a\"],\n","    \"VP\": [\"Verb NP\", \"VNP PP\", \"Verb PP\", \"VP PP\"],\n","    \"Verb\": [\"book\", \"include\", \"prefer\"],\n","    \"Aux\": [\"does\"], \n","    \"VNP\": [\"Verb NP\"],\n","    \"PP\": [\"Prep NP\"],\n","    \"Prep\": [\"from\", \"to\", \"on\", \"near\", \"through\"]\n","}\n","\"\"\"\n","Le seguenti frasi sono:\n","  - Book the flight through Houston\n","  - Does she prefer a morning flight\n","\"\"\"\n","English_phrases = [\"Book the flight through Houston\", \"Does she prefer a morning flight\"]\n"],"metadata":{"id":"kkDOCOEJj0WQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Dothraki Context-free grammar"],"metadata":{"id":"3bXQvsrrI26G"}},{"cell_type":"code","source":["Dothraki_Grammar = {\n","    # Grammatica che produce le frasi seguenti\n","    \"S\": [\"AV PN\", \"NP VP\", \"NP Noun\", \"NP Verb\"],\n","    \"AV\": [\"ANP Verb\" ],\n","    \"ANP\":[\"Aux NP2\"],\n","    \"Aux\":[\"hash\"], \n","    \"NP\": [ \"yera\", \"anha\"], # nominativo\n","    \"NP2\": [\"yer\"], # accusativo\n","    \"PN\": [\"Prep Noun\"],\n","    \"VP\": [\"Verb NP\"],\n","    \"Prep\": [\"ki\"], \n","    \"Noun\": [\"Dothraki\", \"gavork\"],\n","    \"Verb\": [\"astoe\", \"zhilak\"]\n","}\n","\"\"\"\n","Le seguenti frasi sono:\n","  - Do you speak Dothraki ?\n","  - I love you\n","  - I'm hungry\n","\"\"\"\n","Dothraki_phrases = [\"Hash yer astoe ki Dothraki?\", \"Anha zhilak yera\", \"Anha gavork\"]"],"metadata":{"id":"7Uy9kgHSj1x7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Funzioni ausiliarie CKY"],"metadata":{"id":"r_GZL7VYHyM8"}},{"cell_type":"code","source":["def find_matches(CFG, list1, list2, grammar_rules):\n","    \"\"\"\n","    Trova tutte le possibili combinazioni di regole a partire dalle 2 liste in input\n","    Restituisce:\n","    - una matrice di tutte le terne dei match trovati tra le varie combinazioni (es: [[VP, 4, 5], [PP, 6, 5]])\n","    \"\"\"\n","    ret_matches =  np.empty((0,3), int)\n","    \n","    for idx1 in list1: \n","        for idx2 in list2: \n","            A = get_rules(CFG, idx1, idx2, grammar_rules)\n","            ret_matches = np.append(ret_matches, A,0)\n","\n","    return ret_matches"],"metadata":{"id":"nZtt6S_8j5yM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def save_rules(rules, word, matrix, row, col, index, grammar_rules):\n","    \"\"\"\n","    Salva le regole trovate, in particolare:\n","        - salva la lista di chiavi create, nella cella corrente della matrice\n","        - per ognuna, crea una nuova entry nel dizionario\n","        - word: se è None allora sto ragionando su produzioni A->B,C, in alternativa sto \n","          valutando un terminale ad esempio \"flight\"\n","        - index: a che chiave del dizionario grammar_rules sto scrivendo le nuove regole\n","    \"\"\"\n","    #per ogni regola\n","    \"\"\"\n","      Nel primo caso ho una produzione Det=that nel secondo caso invece ho produzioni \n","      piu complesse come A->BC quindi salvo semplicemente le regole in grammar_rules\n","        \n","    \"\"\"\n","\n","\n","    for rule in rules:\n","        #se la cella della matrice che conterrà la matrice finale (matrix) è vuota\n","        if not matrix[row,col]:\n","            #inserisco un array che continee solo l'elemento index\n","            matrix[row,col] = [index]\n","        else:\n","            #Se invece è piena aggiungo index alla lista in essa contenuta\n","            list_id = matrix[row,col]\n","            list_id.append(index)\n","            matrix[row,col] = list_id\n","        grammar_rules[index] = [rule[0], word, None] if word is not None else [rule[0], rule[1], rule[2]]\n","        index += 1\n","    \n","    return index"],"metadata":{"id":"LN0pNFiVj6_2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["grammar_rules {0: ['S', 'Book', None], 1: ['Nominal', 'Book', None], 2: ['Noun', 'Book', None], 3: ['Verb', 'Book', None], 4: ['Det', 'the', None], 5: ['Nominal', 'flight', None], 6: ['Noun', 'flight', None], 7: ['NP', '4', '5']}"],"metadata":{"id":"Z52NMQPYlw8c"}},{"cell_type":"code","source":["\"\"\"\n","  Restituisce le produzioni della grammatica:\n","  Input:\n","  -CFG -> la grammatica che stiamo usando\n","  -id_first -> la parola corrente \n","  -id_second -> una seconda parola (None opzionale)\n","  -grammar_rules -> insieme di regole prodotte\n","  Output:\n","    - una lista vuota, se non trova match\n","    - una terna [left, id_P, id_P] o [[left, T, None]] (es: [S, Book, None])\n","    - una lista di terne (tipicamente per i T) (es: [[S, Book, None], [Noun, Book, None]])\n","\n","\"\"\"\n","def get_rules(CFG, id_first, id_second, grammar_rules, is_terminal = False): \n","\n","    # np.empty crea un nuovo array di grandezza 0-righe e 3-colonne senza inizilizzare i valori \n","    ret_rules =  np.empty((0,3), int)\n","    \n","    if is_terminal:\n","        word = id_first\n","    else:\n","        first = grammar_rules[id_first][0]\n","        second = grammar_rules[id_second][0]\n","        #se esiste second la concateno altrimenti lascio solo first\n","        word = first + \" \" + second if second else first\n","    #print(\"Is Terminal: \" + str(is_terminal))    \n","    #print(\"Word: \" + word)\n","    for key, value in CFG.items():\n","      # se la parola è nella parte destra della regola\n","      # in altre parole se word appartiene alla gramamtica, inizializzo l'array ret_rules\n","        for row in value: \n","            if (word.lower() == row.lower()):\n","                ret_rules = np.append(ret_rules, np.array([[key, id_first, id_second]]),0)\n","    return ret_rules"],"metadata":{"id":"PXRNF5t0j4Op"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#CKY"],"metadata":{"id":"Wy6Z3IQUJdms"}},{"cell_type":"code","source":["def CKY(words, grammar):\n","    \"\"\"\n","    Algoritmo CKY che prende in input:\n","    -la frase prodotta dalla grammatica English/Dothraki dopo aver eseguito lo split in parole\n","    -la grammatica\n","    \"\"\"\n","    #chiave del dizionario grammar_rules a cui scrivo le nuove regole\n","    key = 0     \n","    # grammar_rules è un dizionario con tutte le produzioni\n","    \"\"\"\n","    Esempio\n","    grammar_rules {0: ['S', 'Book', None], 1: ['Nominal', 'Book', None], 2: ['Noun', 'Book', None], 3: ['Verb', 'Book', None], 4: ['Det', 'the', None], 5: ['Nominal', 'flight', None], 6: ['Noun', 'flight', None], 7: ['NP', '4', '5']}\n","    \"\"\"\n","    #insieme delle produzioni della grammatica in questione\n","    grammar_rules = {}\n","    # np.full ritorna un nuovo array di lunghezza e tipo uguali a quelli messi nel campo fill \n","    #in questo caso facciamo un nuovo array di None\n","    parsing_matrix = np.full((len(words),len(words)+1), None)\n","    for j in range(1, len(words)+1):\n","       #assegno la parola in posizione 0 (words[j-1]) che sarà una delle parole della frase da esaminare\n","        current_word = words[j-1] \n","        rules = get_rules(grammar, current_word, None, grammar_rules, True)\n","        key = save_rules(rules, current_word, parsing_matrix, j-1, j, key, grammar_rules)\n","\n","        #range(start, stop, step) parto da j-2, arrivo a -1 e tolgo 1 ogni passo\n","        for i in range(j-2, -1, -1):\n","            for k in range(i+1, j):\n","\n","                B = parsing_matrix[i,k]\n","                #print(B)\n","                C = parsing_matrix[k,j]\n","                #print(\"C: \"+str(C))\n","                if (B is not None) and (C is not None):\n","                    A = find_matches(grammar, B, C, grammar_rules)\n","                    #print(\"A: \"+str(A))\n","                    key = save_rules(A, None, parsing_matrix, i, j, key, grammar_rules)\n","    \n","    return parsing_matrix, grammar_rules\n"],"metadata":{"id":"X14fEfA_j8Xw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Funzioni utili per la visualizzazione dei risultati"],"metadata":{"id":"OAVzJumjJMwk"}},{"cell_type":"code","source":["def print_tree(idx, indentation):\n","    \"\"\"\n","    Stampa l'abero/gli alberi di parsing\n","    \"\"\"\n","    #se l'albero contiene una sola produzione quindi solo ad esempio Verb=book\n","    if not (grammar_rules[idx][2]):\n","        # rigo 1: S -> Verb=book\n","        print(\"\\t\" * indentation, grammar_rules[idx][0], \"=\", grammar_rules[idx][1])\n","    else:\n","        #casi con più produzioni\n","        print(\"\\t\" * indentation, grammar_rules[idx][0], \"->\")\n","        indentation += 1\n","        print_tree(int(grammar_rules[idx][1]), indentation)\n","        print_tree(int(grammar_rules[idx][2]), indentation)\n","\n","\n","def print_matrix():\n","    \n","    #Stampa la matrice del CKY\n","\n","    #np.full restituisce un nuovo array della stessa grandezza dell'array che diamo come parametro nella chiamata\n","    final_matrix = np.full((len(words),len(words)+1), None)\n","    #scorro la matrice\n","    for idx1,row in enumerate(matrix):\n","        for idx2,cell in enumerate(row):\n","            value = []\n","            if cell:\n","                for key in cell:\n","                    value.append(grammar_rules[key][0])\n","            else:\n","                value = None\n","            final_matrix[idx1,idx2] = value\n","    #tabulate serve a stampare la matrice final matrix, a cui aggiungiamo contorni e indici\n","    print(tabulate(final_matrix[:,1:], headers=range(1,len(words)+1), showindex='always', tablefmt='fancy_grid'))\n","\n","\n","\n","\n","def print_result():\n","    \"\"\"\n","    Stampa:\n","    - la frase data in input\n","    - la matrice generata\n","    - Gli alberi di parsing nel caso la frase appartenga alla grammatica\n","    \"\"\"\n","    print(\"Data la seguente frase in input, vediamo il risultato prodotto:\\n\")\n","    print('\\033[1m' + phrase + '\\033[0m'+\"\\n\")\n","    # stampa la matrice\n","    print_matrix()\n","    # dice se la frase appartiene o meno alla grammatica\n","    if (matrix[0,len(words)] is not None):\n","        num_trees = 0\n","        for id in matrix[0,len(words)]:\n","            #se arrivo alla S quindi alla radice allora sono riuscito a produrre un albero\n","            if grammar_rules[id][0] == \"S\":\n","                print(\"-------------------------------------------------------------------\" * (num_trees > 0))\n","                #incremento il conteggio degli alberi prodotti\n","                num_trees += 1\n","                print_tree(id, 0)\n","        if (num_trees == 0):\n","            print(\"La frase %s appartiene alla grammatica.\" % ('\\033[1m' + 'NON' + '\\033[0m'))\n","    else:\n","        print(\"La frase %s appartiene alla grammatica.\" % ('\\033[1m' + 'NON' + '\\033[0m'))"],"metadata":{"id":"GYKraH_SkABr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Parsificazione frasi in Inglese"],"metadata":{"id":"SBg5rUjDJvvx"}},{"cell_type":"code","source":["#r.sub sostituisce i caratteri nel primo parametro con quelli del secondo ''\n","phrase = re.sub(r'[^\\w\\s]', '', English_phrases[0])\n","words = phrase.split()\n","matrix, grammar_rules = CKY(words, English_Grammar)\n","print_result()"],"metadata":{"id":"JEEj6yRzkBUK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644830541428,"user_tz":-60,"elapsed":302,"user":{"displayName":"Aldo Bushaj","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11068623959070267562"}},"outputId":"5a6b663a-ab05-4aa7-d0d0-425d7a9b2a84"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Data la seguente frase in input, vediamo il risultato prodotto:\n","\n","\u001b[1mBook the flight through Houston\u001b[0m\n","\n","╒════╤══════════════════════════════════╤═════════╤═════════════════════╤══════════╤══════════════════════════════════════════╕\n","│    │ 1                                │ 2       │ 3                   │ 4        │ 5                                        │\n","╞════╪══════════════════════════════════╪═════════╪═════════════════════╪══════════╪══════════════════════════════════════════╡\n","│  0 │ ['S', 'Nominal', 'Noun', 'Verb'] │         │ ['S', 'VP', 'VNP']  │          │ ['S', 'VP', 'VNP', 'S', 'VP', 'S', 'VP'] │\n","├────┼──────────────────────────────────┼─────────┼─────────────────────┼──────────┼──────────────────────────────────────────┤\n","│  1 │                                  │ ['Det'] │ ['NP']              │          │ ['NP']                                   │\n","├────┼──────────────────────────────────┼─────────┼─────────────────────┼──────────┼──────────────────────────────────────────┤\n","│  2 │                                  │         │ ['Nominal', 'Noun'] │          │ ['Nominal']                              │\n","├────┼──────────────────────────────────┼─────────┼─────────────────────┼──────────┼──────────────────────────────────────────┤\n","│  3 │                                  │         │                     │ ['Prep'] │ ['PP']                                   │\n","├────┼──────────────────────────────────┼─────────┼─────────────────────┼──────────┼──────────────────────────────────────────┤\n","│  4 │                                  │         │                     │          │ ['NP']                                   │\n","╘════╧══════════════════════════════════╧═════════╧═════════════════════╧══════════╧══════════════════════════════════════════╛\n","\n"," S ->\n","\t Verb = Book\n","\t NP ->\n","\t\t Det = the\n","\t\t Nominal ->\n","\t\t\t Nominal = flight\n","\t\t\t PP ->\n","\t\t\t\t Prep = through\n","\t\t\t\t NP = Houston\n","-------------------------------------------------------------------\n"," S ->\n","\t VP ->\n","\t\t Verb = Book\n","\t\t NP ->\n","\t\t\t Det = the\n","\t\t\t Nominal = flight\n","\t PP ->\n","\t\t Prep = through\n","\t\t NP = Houston\n","-------------------------------------------------------------------\n"," S ->\n","\t VNP ->\n","\t\t Verb = Book\n","\t\t NP ->\n","\t\t\t Det = the\n","\t\t\t Nominal = flight\n","\t PP ->\n","\t\t Prep = through\n","\t\t NP = Houston\n"]}]},{"cell_type":"code","source":["phrase = re.sub(r'[^\\w\\s]', '', English_phrases[1])\n","words = phrase.split()\n","matrix, grammar_rules = CKY(words, English_Grammar)\n","print_result()"],"metadata":{"id":"D0ICsOWfKTxs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644830541428,"user_tz":-60,"elapsed":13,"user":{"displayName":"Aldo Bushaj","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11068623959070267562"}},"outputId":"08e6e5dd-7292-4419-cd8b-92e1644fab53"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Data la seguente frase in input, vediamo il risultato prodotto:\n","\n","\u001b[1mDoes she prefer a morning flight\u001b[0m\n","\n","╒════╤═════════╤═════════╤═══════════════╤═════════╤═════════════════════╤═════════════════════╕\n","│    │ 1       │ 2       │ 3             │ 4       │ 5                   │ 6                   │\n","╞════╪═════════╪═════════╪═══════════════╪═════════╪═════════════════════╪═════════════════════╡\n","│  0 │ ['Aux'] │ ['ANP'] │               │         │ ['S']               │ ['S']               │\n","├────┼─────────┼─────────┼───────────────┼─────────┼─────────────────────┼─────────────────────┤\n","│  1 │         │ ['NP']  │               │         │ ['S']               │ ['S']               │\n","├────┼─────────┼─────────┼───────────────┼─────────┼─────────────────────┼─────────────────────┤\n","│  2 │         │         │ ['S', 'Verb'] │         │ ['S', 'VP', 'VNP']  │ ['S', 'VP', 'VNP']  │\n","├────┼─────────┼─────────┼───────────────┼─────────┼─────────────────────┼─────────────────────┤\n","│  3 │         │         │               │ ['Det'] │ ['NP']              │ ['NP']              │\n","├────┼─────────┼─────────┼───────────────┼─────────┼─────────────────────┼─────────────────────┤\n","│  4 │         │         │               │         │ ['Nominal', 'Noun'] │ ['Nominal']         │\n","├────┼─────────┼─────────┼───────────────┼─────────┼─────────────────────┼─────────────────────┤\n","│  5 │         │         │               │         │                     │ ['Nominal', 'Noun'] │\n","╘════╧═════════╧═════════╧═══════════════╧═════════╧═════════════════════╧═════════════════════╛\n","\n"," S ->\n","\t ANP ->\n","\t\t Aux = Does\n","\t\t NP = she\n","\t VP ->\n","\t\t Verb = prefer\n","\t\t NP ->\n","\t\t\t Det = a\n","\t\t\t Nominal ->\n","\t\t\t\t Nominal = morning\n","\t\t\t\t Noun = flight\n"]}]},{"cell_type":"markdown","source":["#Parsificazione frasi in Dothraki"],"metadata":{"id":"GC3C-P-eKFJP"}},{"cell_type":"code","source":["phrase = re.sub(r'[^\\w\\s]', '', Dothraki_phrases[0])\n","words = phrase.split()\n","matrix, grammar_rules = CKY(words, Dothraki_Grammar)\n","print_result()"],"metadata":{"id":"G-k34tvPkELF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644830541429,"user_tz":-60,"elapsed":12,"user":{"displayName":"Aldo Bushaj","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11068623959070267562"}},"outputId":"58254114-5308-4a9d-9f61-08e43560b21b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Data la seguente frase in input, vediamo il risultato prodotto:\n","\n","\u001b[1mHash yer astoe ki Dothraki\u001b[0m\n","\n","╒════╤═════════╤═════════╤══════════╤══════════╤══════════╕\n","│    │ 1       │ 2       │ 3        │ 4        │ 5        │\n","╞════╪═════════╪═════════╪══════════╪══════════╪══════════╡\n","│  0 │ ['Aux'] │ ['ANP'] │ ['AV']   │          │ ['S']    │\n","├────┼─────────┼─────────┼──────────┼──────────┼──────────┤\n","│  1 │         │ ['NP2'] │          │          │          │\n","├────┼─────────┼─────────┼──────────┼──────────┼──────────┤\n","│  2 │         │         │ ['Verb'] │          │          │\n","├────┼─────────┼─────────┼──────────┼──────────┼──────────┤\n","│  3 │         │         │          │ ['Prep'] │ ['PN']   │\n","├────┼─────────┼─────────┼──────────┼──────────┼──────────┤\n","│  4 │         │         │          │          │ ['Noun'] │\n","╘════╧═════════╧═════════╧══════════╧══════════╧══════════╛\n","\n"," S ->\n","\t AV ->\n","\t\t ANP ->\n","\t\t\t Aux = Hash\n","\t\t\t NP2 = yer\n","\t\t Verb = astoe\n","\t PN ->\n","\t\t Prep = ki\n","\t\t Noun = Dothraki\n"]}]},{"cell_type":"code","source":["phrase = re.sub(r'[^\\w\\s]', '', Dothraki_phrases[1])\n","words = phrase.split()\n","matrix, grammar_rules = CKY(words, Dothraki_Grammar)\n","print_result()"],"metadata":{"id":"4PkMmfAKkEFr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644830541430,"user_tz":-60,"elapsed":10,"user":{"displayName":"Aldo Bushaj","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11068623959070267562"}},"outputId":"cf3b805e-f34c-4965-b7cd-4be3de237240"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Data la seguente frase in input, vediamo il risultato prodotto:\n","\n","\u001b[1mAnha zhilak yera\u001b[0m\n","\n","╒════╤════════╤══════════╤════════╕\n","│    │ 1      │ 2        │ 3      │\n","╞════╪════════╪══════════╪════════╡\n","│  0 │ ['NP'] │ ['S']    │ ['S']  │\n","├────┼────────┼──────────┼────────┤\n","│  1 │        │ ['Verb'] │ ['VP'] │\n","├────┼────────┼──────────┼────────┤\n","│  2 │        │          │ ['NP'] │\n","╘════╧════════╧══════════╧════════╛\n","\n"," S ->\n","\t NP = Anha\n","\t VP ->\n","\t\t Verb = zhilak\n","\t\t NP = yera\n"]}]},{"cell_type":"code","source":["phrase = re.sub(r'[^\\w\\s]', '', Dothraki_phrases[2])\n","words = phrase.split()\n","matrix, grammar_rules = CKY(words, Dothraki_Grammar)\n","print_result()"],"metadata":{"id":"TxChua65kG_e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644830541430,"user_tz":-60,"elapsed":8,"user":{"displayName":"Aldo Bushaj","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11068623959070267562"}},"outputId":"2ff3f167-c9d4-4556-d33f-057ffafa96f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Data la seguente frase in input, vediamo il risultato prodotto:\n","\n","\u001b[1mAnha gavork\u001b[0m\n","\n","╒════╤════════╤══════════╕\n","│    │ 1      │ 2        │\n","╞════╪════════╪══════════╡\n","│  0 │ ['NP'] │ ['S']    │\n","├────┼────────┼──────────┤\n","│  1 │        │ ['Noun'] │\n","╘════╧════════╧══════════╛\n","\n"," S ->\n","\t NP = Anha\n","\t Noun = gavork\n"]}]}]}